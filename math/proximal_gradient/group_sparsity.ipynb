{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Lasso\n",
    "#### Definition\n",
    "The mixed $\\ell_1/\\ell_q$ norm (denoted as $\\Omega(x)$) for group sparisty is computed by:\n",
    "$$\n",
    "\\Omega(x) = \\sum_{g=1}^G{d_g \\lVert x_g \\rVert_q    } \\text{    for any q $\\in$ (1, $\\infty$]},\n",
    "$$\n",
    "where $d_g$ is a positive scalar weight which is usually seleted as $1.0$, $x_g$ is $g$th group from $x$, $G$ is the number of groups in $x$. If $q=2$, the formula above computes the mixed $\\ell_1/\\ell_2$ norm, i.e., $\\Omega(\\mathbf{x}) = \\sum_{g=1}^G{d_g \\lVert \\mathbf{x}_g \\rVert_2}$.\n",
    "\n",
    "In the context of least-squares regression, this regularization is known as the *group Lasso*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proximal Gradient Method for Group Lasso\n",
    "*Step 1.* How do we update variables $x$ if we use group Lasso regularization? \n",
    "\n",
    "\n",
    "We use the same update strategy as Prox-FG and Prox-SG, i.e., \n",
    "$$x_g^{(k)} = \\textbf{prox}_{\\eta_k R}\\left(x_g^{(k-1)} - \\eta_k \\bigtriangledown F(x_g^{(k-1)})\\right).$$ Note that in group sparsity we perform proximal gradient for each group $x_g$ instead of all variables in Prox-FG or randomly selected variables in Prox-SG. \n",
    "\n",
    "*Step 2.* The point here is how do we compute proximal mapping for group Lasso, i.e., $\\textbf{prox}_{\\eta R}(u)$, where $u = \\left(x_g^{(k-1)} - \\eta_k \\bigtriangledown F(x_g^{(k-1)})\\right)$, $\\eta = \\eta_k$ for convenience, $R$ is the group Lasso? \n",
    "\n",
    "\n",
    "When $R$ is the group Lasso, $\\textbf{prox}_{\\eta}(u)$ can be computed by \n",
    "$$\n",
    "\\textbf{prox}_{\\eta}(u) =  \\begin{cases} \n",
    "      u - u \\frac{\\eta \\lambda}{\\lVert u \\rVert_2}, & \\lVert u \\rVert_2 \\geq \\eta \\lambda \\\\\n",
    "      0, & \\lVert u \\rVert_2 \\lt \\eta \\lambda \n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "*Step 3.* Based on above discussion, the update strategy for group Lasso can be defined as:\n",
    "$$\n",
    "u = x_g^{(k-1)} - \\eta_k \\bigtriangledown F(x_g^{(k-1)}) \\\\\n",
    "x_g^{(k)} =  \\begin{cases} \n",
    "      u - u \\frac{\\eta_k \\lambda}{\\lVert u \\rVert_2}, & \\lVert u \\rVert_2 \\geq \\eta_k \\lambda \\\\\n",
    "      0, & \\lVert u \\rVert_2 \\lt \\eta_k \\lambda \n",
    "   \\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBProx-SG\n",
    "\n",
    "#### Case 1. Ball\n",
    "1. We have parameters called $x$, which is divided into $G$ groups, namely $x_1, x_2, \\cdots, x_G$, where $x_g$ might consist of multiple elements.\n",
    "2. We execute the following steps only for groups that contain at least 1 nonzero element:\n",
    "    1. Compute the radius for each group: $\\mathbf{radius}(g) = \\lVert x_g \\rVert_2$\n",
    "    2. Based on the equation at the step $3$ above, we get $\\hat{x}_g$ for $g$th group.\n",
    "    3. Project each element in $\\hat{x}_g$ to their original orthant at the beggining of the epoch. We denote the obtained group as $\\mathbf{proj}(\\hat{x}_g)$. Note that we manupulate single element in the group rather than as a whole.\n",
    "    4. Modify $\\mathbf{proj}(\\hat{x}_g)$ if $\\mathbf{proj}(\\hat{x}_g) > \\mathbf{radius}(g)$:\n",
    "    $$\n",
    "\\mathbf{proj}(\\hat{x}_g) =  \\begin{cases} \n",
    "      \\frac{\\mathbf{proj}(\\hat{x}_g)}{\\lVert \\mathbf{proj}(\\hat{x}_g)  \\rVert_2} \\mathbf{radius}(g), & \\mathbf{proj}(\\hat{x}_g) \\gt \\mathbf{radius}(g) \\\\\n",
    "      \\mathbf{proj}(\\hat{x}_g), & \\text{otherwise} \n",
    "   \\end{cases}\n",
    "    $$\n",
    "    5. Update $x_g$ with $\\mathbf{proj}(\\hat{x}_g)$: $x_g = \\mathbf{proj}(\\hat{x}_g)$\n",
    "    \n",
    "In conclusion, we apply proximal gradient step and projection step to $x_g$ that contains at least $1$ nonzero element, and then limit the $x_g$ within a ball whose radius equals to $\\lVert x_g \\rVert_2$.\n",
    "    \n",
    "    \n",
    "#### Case 2. True Region\n",
    "We denote $\\lambda_i$ as trust region coefficients for group $i$, $G$ as number of groups, $T$ as number of batches, $g_t$ as the gradients on $t$th batch, $\\bar{g}$ as online average of gradients, $g$ as the gradients, $v_i$ as the violation flag for $i$th group, $\\bar{v}_i$ as the online average of violation flag for $i$th group.\n",
    "\n",
    "For each epoch, we have the following algorithm:\n",
    "1. Compute the radius for each group: $\\mathbf{radius}(i) = \\lambda_i \\lVert x_i \\rVert_2, i = 1, 2, \\cdots, G$\n",
    "2. for $t$ in $1, 2, \\cdots, T$:\n",
    "    1. Compute the $F_t$ value with regularizer on $t$th batch.\n",
    "    2. Update the online average of $F$ value: $\\bar{F} = \\frac{t - 1}{t} \\bar{F} + \\frac{1}{t} F_t$\n",
    "    3. Compute the gradients: $g_t = \\begin{cases}\\bigtriangledown F_t(x), & x \\neq 0 \\\\ 0, & x = 0\\end{cases}$.\n",
    "    4. Update the online average of gradients: $\\bar{g} = \\frac{t - 1}{t} \\bar{g} + \\frac{1}{t} {g_t}$\n",
    "    5. Compute the proximal gradient followed by projection step values: $\\mathbf{proj}(\\hat{x}) = \\begin{cases}\\mathbf{proj}(\\hat{x}), & x \\ne 0 \\\\ 0, & x =0\\end{cases}$.\n",
    "    6. Limit the new group value within a ball: $\\mathbf{proj}(\\hat{x}_i) =  \\begin{cases} \n",
    "      \\frac{\\mathbf{proj}(\\hat{x}_i)}{\\lVert \\mathbf{proj}(\\hat{x}_i)  \\rVert_2} \\mathbf{radius}(i), & \\mathbf{proj}(\\hat{x}_i) \\gt \\mathbf{radius}(i) \\\\\n",
    "      \\mathbf{proj}(\\hat{x}_i), & \\text{otherwise} \n",
    "   \\end{cases}$\n",
    "    7. Compute the violation for each group: $v_i = \\begin{cases}1, &\\mathbf{proj}(\\hat{x}_i) \\gt \\mathbf{radius}(i)\\\\ 0, & \\text{otherwise} \\end{cases}$\n",
    "    8. Update the online average of violation for each group: $\\bar{v}_i = \\frac{t - 1}{t} \\bar{v}_i + \\frac{1}{t} v_i$\n",
    "    9. Update $x$: $x = \\mathbf{proj}(\\hat{x}_i)$\n",
    "3. Update trust region coefficients for each group at the end of the epoch:\n",
    "    1. $\\rho = \\frac{\\bar{F_1}- \\bar{F}}{\\alpha^2 \\lVert \\bar{g} \\rVert_2}$, where $\\bar{F_1}$ is the $\\bar{F}$ at previous epoch, $\\alpha$ is selected as $1.0$.\n",
    "    2. $\\lambda_i = \\begin{cases}\\begin{cases}2 \\lambda_i, & v_i \\ge 0.3 \\\\ \\lambda_i, & \\text{otherwise}\\end{cases}, & \\rho \\lt 0.25\\\\\\lambda_i, & 0.25 \\le \\rho \\le 0.75 \\\\\\begin{cases}2 \\lambda_i, & v_i \\ge 0.5 \\\\ \\frac{\\lambda_i}{2}, &v_i = 0\\\\ \\lambda_i, & \\text{otherwise}\\end{cases}, & 0.75 \\lt \\rho \\le 1\\end{cases}$\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
